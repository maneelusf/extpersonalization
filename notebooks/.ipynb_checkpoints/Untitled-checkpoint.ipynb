{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "038fcfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "path = '/home/mkarri/extpersonalization/src'\n",
    "if path not in sys.path:\n",
    "    sys.path.append(path)\n",
    "from models.sequential.GRU4Rec import GRU4Rec\n",
    "from torch.utils.data import DataLoader\n",
    "from helpers import BaseRunner\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pickle\n",
    "from time import time\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "from utils import utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9775347d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../data/ml-1m/args.pkl','rb') as f:\n",
    "    args = pickle.load(f)\n",
    "with open('../data/ml-1m/SeqReader.pkl','rb') as f:\n",
    "    corpus = pickle.load(f)\n",
    "    model = GRU4Rec(args,corpus)\n",
    "file_path = '../model/GRU4Rec/GRU4Rec__ml-1m__0__lr=0.001__l2=0__emb_size=64__hidden_size=64.pt'\n",
    "model.load_state_dict(torch.load(file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c3e53dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU4Recold(GRU4Rec):\n",
    "    reader = 'SeqReader'\n",
    "    runner = 'BaseRunner'\n",
    "    extra_log_args = ['emb_size', 'hidden_size']\n",
    "\n",
    "    @staticmethod\n",
    "    def parse_model_args(parser):\n",
    "        parser.add_argument('--emb_size', type=int, default=64,\n",
    "                            help='Size of embedding vectors.')\n",
    "        parser.add_argument('--hidden_size', type=int, default=64,\n",
    "                            help='Size of hidden vectors in GRU.')\n",
    "        return SequentialModel.parse_model_args(parser)\n",
    "\n",
    "    def __init__(self, args, corpus):\n",
    "        super().__init__(args, corpus)\n",
    "        self.emb_size = args.emb_size\n",
    "        self.hidden_size = args.hidden_size\n",
    "        self._define_params()\n",
    "        self.apply(self.init_weights)\n",
    "\n",
    "    def _define_params(self):\n",
    "        self.i_embeddings = nn.Embedding(self.item_num, self.emb_size)\n",
    "        self.rnn = nn.GRU(input_size=self.emb_size, hidden_size=self.hidden_size, batch_first=True)\n",
    "        # self.pred_embeddings = nn.Embedding(self.item_num, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.emb_size)\n",
    "    def loss(self, out_dict: dict) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        BPR ranking loss with optimization on multiple negative samples (a little different now)\n",
    "        \"Recurrent neural networks with top-k gains for session-based recommendations\"\n",
    "        :param out_dict: contain prediction with [batch_size, -1], the first column for positive, the rest for negative\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        predictions = out_dict['prediction']\n",
    "        pos_pred, neg_pred = predictions[:, 0], predictions[:, 1:]\n",
    "        neg_softmax = (neg_pred - neg_pred.max()).softmax(dim=1)\n",
    "        loss = -((pos_pred[:, None] - neg_pred).sigmoid() * neg_softmax).sum(dim=1).log().mean()\n",
    "        # neg_pred = (neg_pred * neg_softmax).sum(dim=1)\n",
    "        # loss = F.softplus(-(pos_pred - neg_pred)).mean()\n",
    "        # â†‘ For numerical stability, use 'softplus(-x)' instead of '-log_sigmoid(x)'\n",
    "        return loss\n",
    "\n",
    "    def forward(self, feed_dict):\n",
    "        #self.check_list = []\n",
    "        i_ids = feed_dict['item_id']  # [batch_size, -1]\n",
    "        history = feed_dict['history_items']  # [batch_size, history_max]\n",
    "        lengths = feed_dict['lengths']  # [batch_size]\n",
    "\n",
    "        his_vectors = self.i_embeddings(history)\n",
    "\n",
    "        # Sort and Pack\n",
    "        sort_his_lengths, sort_idx = torch.topk(lengths, k=len(lengths))\n",
    "        sort_his_vectors = his_vectors.index_select(dim=0, index=sort_idx)\n",
    "        history_packed = torch.nn.utils.rnn.pack_padded_sequence(\n",
    "            sort_his_vectors, sort_his_lengths.cpu(), batch_first=True)\n",
    "\n",
    "        # RNN\n",
    "        output, hidden = self.rnn(history_packed, None)\n",
    "\n",
    "        # Unsort\n",
    "        unsort_idx = torch.topk(sort_idx, k=len(lengths), largest=False)[1]\n",
    "        rnn_vector = hidden[-1].index_select(dim=0, index=unsort_idx)\n",
    "\n",
    "        # Predicts\n",
    "        # pred_vectors = self.pred_embeddings(i_ids)\n",
    "        pred_vectors = self.i_embeddings(i_ids)\n",
    "        rnn_vector = self.out(rnn_vector)\n",
    "        prediction = (rnn_vector[:, None, :] * pred_vectors).sum(-1)\n",
    "        return {'prediction': prediction.view(feed_dict['batch_size'], -1)}\n",
    "    \n",
    "    def predict_interaction(self,feed_dict,topk = 10):\n",
    "        pred = self.forward(feed_dict)['prediction']\n",
    "        sort_idx = (-pred).argsort(axis=1)\n",
    "        return sort_idx[:topk]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e7eac1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_check = GRU4Recold(args,corpus)\n",
    "model_check.load_state_dict(torch.load(file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "641a2ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## list of all items present\n",
    "item_id = [list(range(1,3707))]\n",
    "## interaction history of items\n",
    "history_items = [[907, 2915,  335, 1248,  514,  853, 3204,  312, 1157, 1161, 1486, 2522,\n",
    "         528, 2006, 1169, 1176, 1193, 3108,  882, 1092]]\n",
    "## user id\n",
    "user_id = [6034]\n",
    "## lengths\n",
    "lengths = [len(x) for x in history_items]\n",
    "batch_size = len(user_id)\n",
    "sample = {'user_id':torch.tensor(user_id),'item_id':torch.tensor(item_id),'history_items':torch.tensor(history_items),\\\n",
    "         'lengths':torch.tensor(lengths),'batch_size':batch_size}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b54ff4cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 158, 3107, 1091,  ..., 2950, 1991,  774]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_check.predict_interaction(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba16d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = dict()\n",
    "for phase in ['train', 'dev', 'test']:\n",
    "    data_dict[phase] = GRU4Rec.Dataset(model_check, corpus, phase)\n",
    "    data_dict[phase].prepare()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7483969c",
   "metadata": {},
   "source": [
    "### Get the BaseRunner model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59016ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseRunnerv1(BaseRunner.BaseRunner):\n",
    "    def train(self, data_dict):\n",
    "        model = data_dict['train'].model\n",
    "        main_metric_results, dev_results = list(), list()\n",
    "        self._check_time(start=True)\n",
    "        try:\n",
    "            for epoch in range(self.epoch):\n",
    "                # Fit\n",
    "                self._check_time()\n",
    "                gc.collect()\n",
    "                torch.cuda.empty_cache()\n",
    "                loss = self.fit(data_dict['train'], epoch=epoch + 1)\n",
    "                training_time = self._check_time()\n",
    "                train_params = {'training_time':training_time,'train_loss':loss}\n",
    "                self.mlflow_log_metrics(train_params,epoch)\n",
    "\n",
    "                # Observe selected tensors\n",
    "                if len(model.check_list) > 0 and self.check_epoch > 0 and epoch % self.check_epoch == 0:\n",
    "                    utils.check(model.check_list)\n",
    "\n",
    "                # Record dev results\n",
    "                dev_result = self.evaluate(data_dict['dev'], self.topk, self.metrics)\n",
    "                self.mlflow_log_metrics(self.head_to_dict(dev_result,'dev'),epoch)\n",
    "                dev_results.append(dev_result)\n",
    "                \n",
    "                main_metric_results.append(dev_result[self.main_metric])\n",
    "                logging_str = 'Epoch {:<5} loss={:<.4f} [{:<3.1f} s]    dev=({})'.format(\n",
    "                    epoch + 1, loss, training_time, utils.format_metric(dev_result))\n",
    "\n",
    "                # Test\n",
    "                if self.test_epoch > 0 and epoch % self.test_epoch  == 0:\n",
    "                    test_result = self.evaluate(data_dict['test'], self.topk, self.metrics)\n",
    "                    logging_str += ' test=({})'.format(utils.format_metric(test_result))\n",
    "                    self.mlflow_log_metrics(self.head_to_dict(dev_result,'test'),epoch)\n",
    "                testing_time = self._check_time()\n",
    "                logging_str += ' [{:<.1f} s]'.format(testing_time)\n",
    "\n",
    "                # Save model and early stop\n",
    "                if max(main_metric_results) == main_metric_results[-1] or \\\n",
    "                        (hasattr(model, 'stage') and model.stage == 1):\n",
    "                    model.save_model()\n",
    "                    logging_str += ' *'\n",
    "                logging.info(logging_str)\n",
    "\n",
    "                if self.early_stop > 0 and self.eval_termination(main_metric_results):\n",
    "                    logging.info(\"Early stop at %d based on dev result.\" % (epoch + 1))\n",
    "                    break\n",
    "        except KeyboardInterrupt:\n",
    "            logging.info(\"Early stop manually\")\n",
    "            exit_here = input(\"Exit completely without evaluation? (y/n) (default n):\")\n",
    "            if exit_here.lower().startswith('y'):\n",
    "                logging.info(os.linesep + '-' * 45 + ' END: ' + utils.get_time() + ' ' + '-' * 45)\n",
    "                exit(1)\n",
    "\n",
    "        # Find the best dev result across iterations\n",
    "        best_epoch = main_metric_results.index(max(main_metric_results))\n",
    "        logging.info(os.linesep + \"Best Iter(dev)={:>5}\\t dev=({}) [{:<.1f} s] \".format(\n",
    "            best_epoch + 1, utils.format_metric(dev_results[best_epoch]), self.time[1] - self.time[0]))\n",
    "        model.load_model()\n",
    "    \n",
    "    def evaluate(self, dataset, topks: list, metrics: list):\n",
    "        \"\"\"\n",
    "        Evaluate the results for an input dataset.\n",
    "        :return: result dict (key: metric@k)\n",
    "        \"\"\"\n",
    "        predictions = self.predict(dataset)\n",
    "        return self.evaluate_method(predictions, topks, metrics)\n",
    "\n",
    "    def predict(self, dataset) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        The returned prediction is a 2D-array, each row corresponds to all the candidates,\n",
    "        and the ground-truth item poses the first.\n",
    "        Example: ground-truth items: [1, 2], 2 negative items for each instance: [[3,4], [5,6]]\n",
    "                 predictions like: [[1,3,4], [2,5,6]]\n",
    "        \"\"\"\n",
    "        dataset.model.eval()\n",
    "        predictions = list()\n",
    "        dl = DataLoader(dataset, batch_size=self.eval_batch_size, shuffle=False, num_workers=self.num_workers,\n",
    "                        collate_fn=dataset.collate_batch, pin_memory=self.pin_memory)\n",
    "        for batch in tqdm(dl, leave=False, ncols=100, mininterval=1, desc='Predict'):\n",
    "            import pdb;pdb.set_trace()\n",
    "            prediction = dataset.model(utils.batch_to_gpu(batch, dataset.model.device))['prediction']\n",
    "            predictions.extend(prediction.cpu().data.numpy())\n",
    "        predictions = np.array(predictions)\n",
    "\n",
    "        if dataset.model.test_all:\n",
    "            rows, cols = list(), list()\n",
    "            for i, u in enumerate(dataset.data['user_id']):\n",
    "                clicked_items = list(dataset.corpus.train_clicked_set[u] | dataset.corpus.residual_clicked_set[u])\n",
    "                idx = list(np.ones_like(clicked_items) * i)\n",
    "                rows.extend(idx)\n",
    "                cols.extend(clicked_items)\n",
    "            predictions[rows, cols] = -np.inf\n",
    "\n",
    "        return predictions\n",
    "\n",
    "    def print_res(self, dataset) -> str:\n",
    "        \"\"\"\n",
    "        Construct the final result string before/after training\n",
    "        :return: test result string\n",
    "        \"\"\"\n",
    "        result_dict = self.evaluate(dataset, self.topk, self.metrics)\n",
    "        #res_str = '(' + utils.format_metric(result_dict) + ')'\n",
    "        return result_dict\n",
    "    \n",
    "    def fit(self, dataset, epoch=-1) -> float:\n",
    "        model = dataset.model\n",
    "        if model.optimizer is None:\n",
    "            model.optimizer = self._build_optimizer(model)\n",
    "        dataset.actions_before_epoch()  # must sample before multi thread start\n",
    "\n",
    "        model.train()\n",
    "        loss_lst = list()\n",
    "        dl = DataLoader(dataset, batch_size=self.batch_size, shuffle=True, num_workers=self.num_workers,\n",
    "                        collate_fn=dataset.collate_batch, pin_memory=self.pin_memory)\n",
    "        for batch in tqdm(dl, leave=False, desc='Epoch {:<3}'.format(epoch), ncols=100, mininterval=1):\n",
    "            batch = utils.batch_to_gpu(batch, model.device)\n",
    "            model.optimizer.zero_grad()\n",
    "            out_dict = model(batch)\n",
    "            loss = model.loss(out_dict)\n",
    "            loss.backward()\n",
    "            model.optimizer.step()\n",
    "            loss_lst.append(loss.detach().cpu().data.numpy())\n",
    "        return np.mean(loss_lst).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392ae614",
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = BaseRunnerv1(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c9c4a5",
   "metadata": {},
   "source": [
    "## Interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a19d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## list of all items present\n",
    "item_id = [list(range(1,3707))]\n",
    "## interaction history of items\n",
    "history_items = [[907, 2915,  335, 1248,  514,  853, 3204,  312, 1157, 1161, 1486, 2522,\n",
    "         528, 2006, 1169, 1176, 1193, 3108,  882, 1092]]\n",
    "## user id\n",
    "user_id = [6034]\n",
    "## lengths\n",
    "lengths = [len(x) for x in history_items]\n",
    "batch_size = len(user_id)\n",
    "sample = {'user_id':torch.tensor(user_id),'item_id':torch.tensor(item_id),'history_items':torch.tensor(history_items),\\\n",
    "         'lengths':torch.tensor(lengths),'batch_size':batch_size}\n",
    "# dl = DataLoader(data_dict['test'], batch_size=256, shuffle=False, num_workers=5,\n",
    "#                         collate_fn=data_dict['test'].collate_batch, pin_memory=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d45a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_check(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718976a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model_check(sample)['prediction']\n",
    "evaluations = dict()\n",
    "sort_idx = (-pred).argsort(axis=1)\n",
    "#gt_rank = np.argwhere(sort_idx == 0)[:, 1] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c26515",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2990e7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in dl:\n",
    "    import pdb;pdb.set_trace()\n",
    "    model_check(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f8d6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(data_dict['train'], batch_size=256, shuffle=False, num_workers=5,\n",
    "                        collate_fn=data_dict['train'].collate_batch, pin_memory=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec176ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = list()\n",
    "dl = DataLoader(data_dict['test'], batch_size=256, shuffle=False, num_workers=5,\n",
    "                        collate_fn=data_dict['test'].collate_batch, pin_memory=0)\n",
    "for batch in tqdm(dl, leave=False, ncols=100, mininterval=1, desc='Predict'):\n",
    "    prediction = data_dict['test'].model(utils.batch_to_gpu(batch, data_dict['test'].model.device))['prediction']\n",
    "    predictions.extend(prediction.cpu().data.numpy())\n",
    "predictions = np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4f0297",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5174bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluations = dict()\n",
    "sort_idx = (-predictions).argsort(axis=1)\n",
    "gt_rank = np.argwhere(sort_idx == 0)[:, 1] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272b208c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sort_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f628c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbf806b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8570e4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27ea112",
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_dict['test'].model.test_all:\n",
    "    print('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b27e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_items = [1584, 3385, 2862, 3106,  533, 3579, 2214,  568, 1827, 2670, 1272, 2921,\n",
    "        3337,   68, 2659,  725, 3585, 1629, 2742,  124, 1471,  395, 1667, 3166,\n",
    "        3422, 1698, 1437, 2435, 2303,  534, 3410, 1083, 2391, 2970,  166,  374,\n",
    "        1813,  582,  455, 2460, 3561, 2304,  413, 1816, 1600, 3132,  182, 1054,\n",
    "        3523, 2507, 2819, 3415, 2545, 2871,  559, 2083, 1699,  229, 3633, 3626,\n",
    "        1921, 3238,  513, 1958, 3006, 1513, 2524, 1229, 2233, 1348, 3497, 1352,\n",
    "        2399, 3003, 1157, 3452, 3347, 1824, 3152,  707,   88,  105,  241, 1617,\n",
    "        1346, 3645, 3561, 3022, 2208,  804, 1445, 2593,  596, 3349, 2211,  931,\n",
    "         165, 3655,  886, 3155]\n",
    "user_id = 6034\n",
    "pos_items = [ 419, 1856, 1328, 2746, 1605, 1345,  662,  365, 1862,  424, 2516,  941,\n",
    "        1661, 2105,  316,  407,  416, 1565, 1972,  815]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0a213b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(data_dict['dev'], batch_size=256, shuffle=False, num_workers=5,\n",
    "                        collate_fn=data_dict['dev'].collate_batch, pin_memory=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e348eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prediction = dataset.model(utils.batch_to_gpu(batch, dataset.model.device))['prediction']\n",
    "            predictions.extend(prediction.cpu().data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcfc874",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in dl:\n",
    "    model_check(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5699da2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
