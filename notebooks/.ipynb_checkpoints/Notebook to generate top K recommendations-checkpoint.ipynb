{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "038fcfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "curr_path = os.getcwd().split('/')\n",
    "curr_path = curr_path[:len(curr_path) - 1]\n",
    "curr_path.append('src')\n",
    "curr_path = '/'.join(curr_path)\n",
    "if curr_path not in sys.path:\n",
    "    sys.path.append(curr_path)\n",
    "from models.sequential.GRU4Rec import GRU4Rec\n",
    "from torch.utils.data import DataLoader\n",
    "from helpers import BaseRunner\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pickle\n",
    "from time import time\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "from utils import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9775347d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## loading arguments from args.pkl(run argcorpus.py with model inputs from Command line i.e. \n",
    "# python argscorpus.py --dataset ml-1m --model_name GRU4Rec)\n",
    "with open('../data/ml-1m/args.pkl','rb') as f:\n",
    "    args = pickle.load(f)\n",
    "with open('../data/ml-1m/SeqReader.pkl','rb') as f:\n",
    "    corpus = pickle.load(f)\n",
    "    model = GRU4Rec(args,corpus)\n",
    "## loading file path\n",
    "file_path = '../model/GRU4Rec/GRU4Rec__ml-1m__0__lr=0.001__l2=0__emb_size=64__hidden_size=64.pt'\n",
    "model.load_state_dict(torch.load(file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c3e53dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU4Recold(GRU4Rec):\n",
    "    \n",
    "    def predict_interaction(self,feed_dict,topk = 10):\n",
    "        pred = self.forward(feed_dict)['prediction']\n",
    "        sort_idx = (-pred).argsort(axis=1)\n",
    "        return sort_idx[0][:topk]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e7eac1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_check = GRU4Recold(args,corpus)\n",
    "model_check.load_state_dict(torch.load(file_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c28d06a",
   "metadata": {},
   "source": [
    "### Interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f1c5cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "## list of all items present\n",
    "item_id = [list(range(1,model_check.item_num))]\n",
    "## interaction history of items\n",
    "history_items = [[907, 2915,  335, 1248,  514,  853, 3204,  312, 1157, 1161, 1486, 2522,\n",
    "         528, 2006, 1169, 1176, 1193, 3108,  882, 1092]]\n",
    "## user id\n",
    "user_id = [6034]\n",
    "## lengths\n",
    "lengths = [len(x) for x in history_items]\n",
    "batch_size = len(user_id)\n",
    "sample = {'user_id':torch.tensor(user_id),'item_id':torch.tensor(item_id),'history_items':torch.tensor(history_items),\\\n",
    "         'lengths':torch.tensor(lengths),'batch_size':batch_size}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10ce6bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions = model_check.predict_interaction(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d79a203b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GRU4Recold(\n",
       "  (i_embeddings): Embedding(3707, 64)\n",
       "  (rnn): GRU(64, 64, batch_first=True)\n",
       "  (out): Linear(in_features=64, out_features=64, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61eafda7-a5c1-4859-8429-a9e7901eaf29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 158, 3107, 1091,  ..., 2950, 1991,  774]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7483969c",
   "metadata": {},
   "source": [
    "### Get the BaseRunner model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
